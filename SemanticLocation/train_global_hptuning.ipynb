{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "0\n",
      "52\n",
      "------------------\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/ranking.py:542: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n",
      "------------------\n",
      "2\n",
      "78\n",
      "------------------\n",
      "3\n",
      "152\n",
      "------------------\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/ranking.py:542: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "------------------\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/ranking.py:542: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n",
      "------------------\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/ranking.py:542: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "------------------\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/ranking.py:542: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "------------------\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/ranking.py:542: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n",
      "------------------\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/ranking.py:542: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "0.694498286596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/ranking.py:542: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from calculate_confusion_matrix import calculate_confusion_matrix\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from utils import one_hot_encoder\n",
    "\n",
    "n_boot = 10\n",
    "split = 0.95\n",
    "np.random.seed(seed=0)\n",
    "\n",
    "ft_dir = 'features_long/'\n",
    "\n",
    "# list feature files\n",
    "files = os.listdir(ft_dir)\n",
    "files = files[:20]\n",
    "\n",
    "# reading top locations\n",
    "with open('top_locations.dat', 'rb') as f:\n",
    "    location_top = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "feature_all = []\n",
    "target_all = []\n",
    "\n",
    "for filename in files:\n",
    "    with open(ft_dir+filename, 'rb') as f:  \n",
    "        feature, target = pickle.load(f)\n",
    "\n",
    "        # only keeping locations in location_top\n",
    "        ind = np.array([], int)\n",
    "        for (i,loc) in enumerate(target['location']):\n",
    "            if loc in location_top:\n",
    "                ind = np.append(ind, i)\n",
    "        feature = feature.loc[ind,:]\n",
    "        target = target.loc[ind]\n",
    "        \n",
    "        feature = feature.reset_index(drop=True)\n",
    "        target = target.reset_index(drop=True)\n",
    "        \n",
    "        feature_all.append(feature)\n",
    "        target_all.append(target)\n",
    "        \n",
    "    f.close()\n",
    "\n",
    "confs = []\n",
    "aucs = []\n",
    "aucs_mean = []\n",
    "labels = []\n",
    "inds = np.arange(0,len(feature_all),1)\n",
    "inds_split = int(np.floor(split*len(feature_all)))\n",
    "\n",
    "for i in range(n_boot):\n",
    "    \n",
    "#     print('------------------')\n",
    "#     print(i)\n",
    "    \n",
    "    # training set\n",
    "    np.random.shuffle(inds)\n",
    "    ind_train = inds[:inds_split]\n",
    "    ind_test = inds[inds_split:]\n",
    "    \n",
    "    x_train = pd.concat([feature_all[j] for j in ind_train], axis=0)\n",
    "    y_train = pd.concat([target_all[j]['location'] for j in ind_train], axis=0)\n",
    "    x_train = x_train.reset_index(drop=True)\n",
    "    y_train = y_train.reset_index(drop=True)\n",
    "    \n",
    "    # test set\n",
    "    x_test = pd.concat([feature_all[j] for j in ind_test], axis=0)\n",
    "    y_test = pd.concat([target_all[j]['location'] for j in ind_test], axis=0)\n",
    "    x_test = x_test.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "    \n",
    "    # remove foursquare features (sensor)\n",
    "#     x_train = x_train.drop(['fsq 0','fsq 1','fsq 2','fsq 3','fsq 4','fsq 5','fsq 6','fsq 7','fsq 8','fsq distance'],axis=1)\n",
    "#     x_test = x_test.drop(['fsq 0','fsq 1','fsq 2','fsq 3','fsq 4','fsq 5','fsq 6','fsq 7','fsq 8','fsq distance'],axis=1)\n",
    "#     x_train = x_train.reset_index(drop=True)\n",
    "#     x_test = x_test.reset_index(drop=True)\n",
    "    \n",
    "    # model (sensor)\n",
    "#     gbm = xgb.XGBClassifier(max_depth=6, n_estimators=50, learning_rate=0.05, nthread=12, subsample=0.25, \\\n",
    "#                         colsample_bytree=0.5, max_delta_step=0, gamma=3, objective='mlogloss', reg_alpha=0.5, \\\n",
    "#                         missing=np.nan)\n",
    "    \n",
    "    # model (sensor + foursquare)\n",
    "    gbm = xgb.XGBClassifier(max_depth=5, n_estimators=1000, learning_rate=0.1, nthread=12, subsample=0.8, \\\n",
    "                        colsample_bytree=0.8, max_delta_step=0, gamma=0, objective='mlogloss', \\\n",
    "                        reg_alpha=0, reg_lambda=1, \\\n",
    "                        missing=np.nan, min_child_weight=1, scale_pos_weight=1, seed=27)\n",
    "    \n",
    "    # fitting model\n",
    "    gbm.fit(x_train, y_train, eval_set=[(x_train,y_train),(x_test, y_test)], eval_metric='mlogloss', verbose=False,\\\n",
    "           early_stopping_rounds=50)\n",
    "    print(gbm.best_iteration)\n",
    "#     gbm.fit(x_train, y_train)\n",
    "    \n",
    "    # training performance\n",
    "    y_pred = gbm.predict(x_train)\n",
    "    conf_train, roc_auc_train = calculate_confusion_matrix(y_pred, y_train)\n",
    "\n",
    "    # test\n",
    "    y_pred = gbm.predict(x_test)\n",
    "    conf, roc_auc = calculate_confusion_matrix(y_pred, y_test)\n",
    "    \n",
    "    labels.append(np.unique(y_test))\n",
    "    confs.append(conf)\n",
    "    aucs.append(roc_auc)\n",
    "    aucs_mean.append(np.nanmean(roc_auc))\n",
    "\n",
    "#     print(np.unique(y_test))\n",
    "#     print(roc_auc_train, np.nanmean(roc_auc_train))\n",
    "#     print(roc_auc, np.nanmean(roc_auc))\n",
    "\n",
    "print(np.nanmean(np.array(aucs_mean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
