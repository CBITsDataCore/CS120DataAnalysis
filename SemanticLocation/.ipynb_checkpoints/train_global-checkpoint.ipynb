{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"Nightlife Spot (Bar, Club)\"' '\"Spiritual (Church, Temple, Etc.)\"'\n",
      " '\"Outdoors & Recreation\"'\n",
      " '\"Arts & Entertainment (Theater, Music Venue, Etc.)\"' '\"Work\"'\n",
      " '\"Professional or Medical Office\"' '\"Another\\'s Home\"'\n",
      " '\"Food (Restaurant, Cafe)\"' '\"Home\"' '\"Shop or Store\"']\n",
      "------------------\n",
      "0\n",
      "['\"Another\\'s Home\"' '\"Food (Restaurant, Cafe)\"' '\"Home\"'\n",
      " '\"Outdoors & Recreation\"' '\"Professional or Medical Office\"'\n",
      " '\"Shop or Store\"']\n",
      "[[  0.   0.   2.   0.   0.   3.   9.]\n",
      " [  0.   0.   1.   0.   0.   0.   1.]\n",
      " [  0.   0.  41.   0.   0.   0.   0.]\n",
      " [  0.   0.   1.   0.   0.   0.   0.]\n",
      " [  0.   0.   6.   0.   0.   1.   6.]\n",
      " [  1.   0.   1.   0.   0.  12.   1.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.]]\n",
      "[ 0.41764706         nan  0.89423077         nan         nan  0.85357143\n",
      "  0.5       ]\n",
      "------------------\n",
      "1\n",
      "['\"Arts & Entertainment (Theater, Music Venue, Etc.)\"'\n",
      " '\"Food (Restaurant, Cafe)\"' '\"Home\"' '\"Nightlife Spot (Bar, Club)\"'\n",
      " '\"Outdoors & Recreation\"' '\"Shop or Store\"'\n",
      " '\"Spiritual (Church, Temple, Etc.)\"' '\"Work\"']\n",
      "[[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   1.   4.   0.   0.   2.   4.   0.   1.]\n",
      " [  0.   0.   1.   5.   0.   0.   1.   6.   0.   2.]\n",
      " [  0.   0.   4.  58.   0.   0.   0.   2.   0.   2.]\n",
      " [  2.   0.   3.   0.   0.   0.   0.   2.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   6.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   2.   1.   0.   0.   0.  40.   0.   0.]\n",
      " [  1.   0.   3.   2.   0.   0.   0.   5.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   7.   0.  34.]]\n",
      "[ 0.5                nan  0.49828113  0.88375136         nan         nan\n",
      "  0.5         0.76614987         nan  0.9142925 ]\n",
      "------------------\n",
      "2\n",
      "['\"Another\\'s Home\"' '\"Arts & Entertainment (Theater, Music Venue, Etc.)\"'\n",
      " '\"Food (Restaurant, Cafe)\"' '\"Home\"' '\"Outdoors & Recreation\"'\n",
      " '\"Shop or Store\"' '\"Spiritual (Church, Temple, Etc.)\"' '\"Work\"']\n",
      "[[  0.   0.   1.   0.   0.   1.   0.   0.]\n",
      " [  0.   0.   0.   1.   0.   2.   0.   0.]\n",
      " [  0.   0.   0.   1.   0.  14.   0.   0.]\n",
      " [  0.   0.   0.  56.   0.   1.   0.   0.]\n",
      " [  0.   0.   2.   0.   0.   8.   0.   1.]\n",
      " [  1.   0.   1.   6.   0.  13.   0.   4.]\n",
      " [  0.   0.   2.   0.   0.   0.   0.   1.]\n",
      " [  0.   0.   0.   0.   0.   1.   0.   0.]]\n",
      "[ 0.49137931         nan  0.43243243  0.92806604         nan  0.58457792\n",
      "         nan  0.4954955 ]\n",
      "------------------\n",
      "3\n",
      "['\"Another\\'s Home\"' '\"Food (Restaurant, Cafe)\"' '\"Home\"'\n",
      " '\"Nightlife Spot (Bar, Club)\"' '\"Professional or Medical Office\"'\n",
      " '\"Shop or Store\"' '\"Work\"']\n",
      "[[  0.   0.   5.   0.   0.   2.   0.]\n",
      " [  0.   0.   2.   0.   0.   1.   0.]\n",
      " [  0.   0.  49.   0.   0.   0.   0.]\n",
      " [  0.   0.   1.   0.   0.   0.   0.]\n",
      " [  0.   0.   1.   0.   0.   0.   0.]\n",
      " [  0.   0.   1.   0.   0.   0.   0.]\n",
      " [  0.   0.  32.   0.   0.   1.   0.]]\n",
      "[        nan         nan  0.76923077         nan         nan  0.49450549\n",
      "         nan]\n",
      "------------------\n",
      "4\n",
      "['\"Another\\'s Home\"' '\"Arts & Entertainment (Theater, Music Venue, Etc.)\"'\n",
      " '\"Home\"' '\"Outdoors & Recreation\"' '\"Shop or Store\"']\n",
      "[[  0.   0.   0.   0.   0.   0.   1.]\n",
      " [  0.   0.   0.   0.   0.   1.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   1.  13.   0.   6.   0.]\n",
      " [  0.   0.   2.   0.   0.   0.   0.]\n",
      " [  0.   0.   1.   1.   0.   3.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.]]\n",
      "[        nan         nan  0.5         0.73095238         nan  0.59736842\n",
      "  0.5       ]\n",
      "subjects skipped because of lack of data\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "At least 2 points are needed to compute area under curve, but x.shape = 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-b1890fa21fef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mconf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m'------------------'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sohrob/Dropbox/Code/MATLAB/CS120/SemanticLocation/calculate_confusion_matrix.pyc\u001b[0m in \u001b[0;36mcalculate_confusion_matrix\u001b[1;34m(y, y_t)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m                 \u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_bin\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_t_bin\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m                 \u001b[0mroc_auc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_auc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/metrics/ranking.pyc\u001b[0m in \u001b[0;36mauc\u001b[1;34m(x, y, reorder)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         raise ValueError('At least 2 points are needed to compute'\n\u001b[1;32m---> 85\u001b[1;33m                          ' area under curve, but x.shape = %s' % x.shape)\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[0mdirection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: At least 2 points are needed to compute area under curve, but x.shape = 1"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import xgboost\n",
    "from calculate_confusion_matrix import calculate_confusion_matrix\n",
    "\n",
    "ft_dir = 'features/'\n",
    "\n",
    "files = os.listdir(ft_dir)\n",
    "\n",
    "feature_all = []\n",
    "state_all = []\n",
    "for filename in files:\n",
    "    with open(ft_dir+filename) as f:  \n",
    "        feature, state = pickle.load(f)\n",
    "        feature_all.append(feature)\n",
    "        state_all.append(state)\n",
    "    f.close()\n",
    "\n",
    "with open('top10.dat') as f:\n",
    "    state_top10 = pickle.load(f)\n",
    "f.close()\n",
    "for (i,s) in enumerate(state_top10):\n",
    "    state_top10[i] = s.replace('\"','')\n",
    "    state_top10[i] = s.replace('[','')\n",
    "    state_top10[i] = s.replace(']','')\n",
    "    \n",
    "print state_top10\n",
    "\n",
    "confs = []\n",
    "aucs = []\n",
    "labels = []\n",
    "\n",
    "for i in range(len(feature_all)):\n",
    "    \n",
    "    if i==5:\n",
    "        print 'subject skipped because of lack of data'\n",
    "        continue\n",
    "    \n",
    "    #creating train and test sets\n",
    "    x_train = np.array([])\n",
    "    y_train = np.array([])\n",
    "    for j in range(len(feature_all)):\n",
    "        if j!=i:\n",
    "            for k in range(len(state_all[j])):\n",
    "                if state_all[j][k] in state_top10:\n",
    "                    if x_train.size==0:\n",
    "                        x_train = np.array([feature_all[j][k,:]])\n",
    "                        y_train = np.array(state_all[j][k])\n",
    "                    else:\n",
    "                        x_train = np.append(x_train, [feature_all[j][k,:]], axis=0)\n",
    "                        y_train = np.append(y_train, state_all[j][k])\n",
    "    \n",
    "    x_test = np.array([])\n",
    "    y_test = np.array([])\n",
    "    for j in range(len(state_all[i])):\n",
    "        if state_all[i][j] in state_top10:\n",
    "            if x_test.size==0:\n",
    "                x_test = np.array([feature_all[i][j,:]])\n",
    "                y_test = np.array(state_all[i][j])\n",
    "            else:\n",
    "                x_test = np.append(x_test, [feature_all[i][j,:]], axis=0)\n",
    "                y_test = np.append(y_test, state_all[i][j])\n",
    "\n",
    "    #train\n",
    "    gbm = xgboost.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05).fit(x_train, y_train)\n",
    "\n",
    "    #test\n",
    "    predictions = gbm.predict(x_test)\n",
    "\n",
    "    conf, roc_auc = calculate_confusion_matrix(predictions, y_test)\n",
    "    print '------------------'\n",
    "    print i\n",
    "    print np.unique(y_test)\n",
    "    print conf\n",
    "    print roc_auc\n",
    "    labels.append(np.unique(y_test))\n",
    "    confs.append(conf)\n",
    "    aucs.append(roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"Another\\'s Home\"' '\"Food (Restaurant, Cafe)\"' '\"Home\"'\n",
      " '\"Outdoors & Recreation\"' '\"Professional or Medical Office\"'\n",
      " '\"Shop or Store\"']\n",
      "[[  0.   0.   2.   0.   0.   3.   9.]\n",
      " [  0.   0.   1.   0.   0.   0.   1.]\n",
      " [  0.   0.  41.   0.   0.   0.   0.]\n",
      " [  0.   0.   1.   0.   0.   0.   0.]\n",
      " [  0.   0.   6.   0.   0.   1.   6.]\n",
      " [  1.   0.   1.   0.   0.  12.   1.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.]]\n",
      "[ 0.41764706         nan  0.89423077         nan         nan  0.85357143\n",
      "  0.5       ]\n"
     ]
    }
   ],
   "source": [
    "print np.unique(y_test)\n",
    "print conf\n",
    "print roc_auc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
