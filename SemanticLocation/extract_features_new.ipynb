{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "from get_data_at_location import get_data_at_location\n",
    "from calculate_confusion_matrix import calculate_confusion_matrix\n",
    "import math\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from scipy import stats\n",
    "from count_transitions import count_transitions\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "\n",
    "save_results = True\n",
    "\n",
    "data_dir = 'data/'\n",
    "\n",
    "feature_label = np.array(['lgt mean','lgt std','aud mean','aud std','frq mean','frq std','screen','still','tilt','foot','unknown',\\\n",
    "                         'still_onfoot','still_tilting','mobilyze','phone','contacts','messaging','chrome','facebook','messenger','twitter',\\\n",
    "                         'video','camera','n call','n sms','n missed','n wifi','lat','lng','loc var','temp','dew point','condition',\\\n",
    "                          'delta_t','mid hour','dow start','dow end'])\n",
    "\n",
    "fsq_map = {'Nightlife Spot':'Nightlife Spot (Bar, Club)', 'Outdoors & Recreation':'Outdoors & Recreation',\\\n",
    "          'Arts & Entertainment':'Arts & Entertainment (Theater, Music Venue, Etc.)',\\\n",
    "          'Professional & Other Places':'Professional or Medical Office',\\\n",
    "          'Food':'Food (Restaurant, Cafe)', 'Residence':'Home', 'Shop & Service':'Shop or Store'}\n",
    "\n",
    "# building one hot encoder for foursquare locations (as extra features)\n",
    "state7 = np.array(fsq_map.values()+['Unknown'])\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(state7)\n",
    "state7_code = le.transform(state7)\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(state7_code.reshape(-1, 1))\n",
    "\n",
    "subjects = os.listdir(data_dir)\n",
    "#subjects = [subjects[0]]\n",
    "\n",
    "for (cnt,subj) in enumerate(subjects):\n",
    "    subject_dir = data_dir + subj + '/'\n",
    "    samples = os.listdir(subject_dir)\n",
    "    print str(cnt) + ' ' + subj\n",
    "    feature = np.array([])\n",
    "    state = np.array([])\n",
    "    state_fsq = np.array([])\n",
    "    for (i,samp) in enumerate(samples):\n",
    "        sensor_dir = subject_dir + samp + '/'\n",
    "        sensors = os.listdir(sensor_dir)\n",
    "        if not ('eml.csv' in sensors):\n",
    "            print 'subject '+subj+' does not have location report data at '+samp\n",
    "            continue\n",
    "        else:\n",
    "            filename = sensor_dir+'eml.csv'\n",
    "            data_eml = pd.read_csv(filename, delimiter='\\t', header=None)\n",
    "            loc = data_eml[6][0]\n",
    "            loc = loc[1:len(loc)-1]\n",
    "            loc = loc.replace('\"','')\n",
    "        \n",
    "        if 'fsq2.csv' in sensors:\n",
    "            data_fsq = pd.read_csv(sensor_dir+'fsq2.csv', delimiter='\\t', header=None)\n",
    "            loc_fsq = data_fsq.loc[10,1]\n",
    "            distance_fsq = float(data_fsq.loc[11,1])\n",
    "            \n",
    "            # converting foursquare category name to standard name\n",
    "            if loc_fsq in fsq_map:\n",
    "                loc_fsq = fsq_map[loc_fsq]\n",
    "            else:\n",
    "                loc_fsq = 'Unknown'\n",
    "                \n",
    "        else:\n",
    "            loc_fsq = 'Unknown'\n",
    "            distance_fsq = np.nan\n",
    "        \n",
    "        ft_row = np.array([])\n",
    "        \n",
    "        # light\n",
    "        if 'lgt.csv' in sensors:\n",
    "            data = pd.read_csv(sensor_dir+'lgt.csv', delimiter='\\t', header=None)\n",
    "            lgt = data[:][1]\n",
    "            ft_row = np.append(ft_row, [np.nanmean(lgt), np.nanstd(lgt), np.sum(lgt==0)/float(lgt.size), \\\n",
    "                                       np.sum(np.diff(np.sign(lgt-np.nanmean(lgt))))/float(lgt.size),\\\n",
    "                                       stats.skew(lgt), stats.kurtosis(lgt)]) # prop. zero-crossings\n",
    "        else:\n",
    "            ft_row = np.append(ft_row, [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "\n",
    "        # audio\n",
    "        if 'aud.csv' in sensors:\n",
    "            data = pd.read_csv(sensor_dir+'aud.csv', delimiter='\\t', header=None)\n",
    "            ft_row = np.append(ft_row, [np.nanmean(data[:][1]), np.nanstd(data[:][1]), \\\n",
    "                                        stats.skew(data[:][1]), stats.kurtosis(data[:][1]),\\\n",
    "                                        np.nanmean(data[:][2]), np.nanstd(data[:][2]),\\\n",
    "                                        stats.skew(data[:][2]), stats.kurtosis(data[:][2])])\n",
    "        else:\n",
    "            ft_row = np.append(ft_row, [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "\n",
    "        # screen\n",
    "        if 'scr.csv' in sensors:\n",
    "            data = pd.read_csv(sensor_dir+'scr.csv', delimiter='\\t', header=None)\n",
    "            if data[:][0].size>=2:\n",
    "                deltat = data[0][data[0][:].size-1] - data[0][0]\n",
    "                if deltat!=0:\n",
    "                    scr_dur = np.array([])\n",
    "                    scr_frq = 0\n",
    "                    for j in range(data[1][:].size-1):\n",
    "                        if data[1][j]=='True' and data[1][j+1]=='False':\n",
    "                            scr_dur = np.append(scr_dur, data[0][j+1]-data[0][j])\n",
    "                            scr_frq += 1\n",
    "                    ft_row = np.append(ft_row, [scr_frq/float(deltat), np.mean(scr_dur), np.std(scr_dur)])\n",
    "                else:\n",
    "                    ft_row = np.append(ft_row, [np.nan,np.nan,np.nan])\n",
    "            else:\n",
    "                ft_row = np.append(ft_row, [0,0,0])\n",
    "        else:\n",
    "            ft_row = np.append(ft_row, [0,0,0])\n",
    "        \n",
    "        # activity\n",
    "        if 'act.csv' in sensors:\n",
    "            data = pd.read_csv(sensor_dir+'act.csv', delimiter='\\t', header=None)\n",
    "            n = float(data[0][:].size)\n",
    "            per_still = np.sum(data[1][:]=='STILL')/n\n",
    "            per_tilt = np.sum(data[1][:]=='TILTING')/n\n",
    "            per_onfoot = np.sum(data[1][:]=='ONFOOT')/n\n",
    "            per_unknown = np.sum(data[1][:]=='UNKNOWN')/n\n",
    "            n_trans1 = count_transitions(data[1][:],'STILL','ONFOOT')/n\n",
    "            n_trans2 = count_transitions(data[1][:],'STILL','TILTING')/n\n",
    "            n_trans3 = count_transitions(data[1][:],'STILL','UNKNOWN')/n\n",
    "            n_trans4 = count_transitions(data[1][:],'ONFOOT','UNKNOWN')/n\n",
    "            ft_row = np.append(ft_row, [per_still, per_tilt, per_onfoot, per_unknown, n_trans1, n_trans2,\\\n",
    "                                       n_trans3, n_trans4])\n",
    "        else:\n",
    "            ft_row = np.append(ft_row, [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan])\n",
    "        \n",
    "        # apps\n",
    "        if 'app.csv' in sensors:\n",
    "            data = pd.read_csv(sensor_dir+'app.csv', delimiter='\\t', header=None)\n",
    "            ft_row = np.append(ft_row, [np.sum(data[2][:]=='Messaging'),\\\n",
    "                                        np.sum(data[2][:]=='Facebook'),\\\n",
    "                                        np.sum(data[2][:]=='Chrome'),\\\n",
    "                                        np.sum(data[2][:]=='Mobilyze'),\\\n",
    "                                        np.sum(data[2][:]=='Phone'),\\\n",
    "                                        np.sum(data[2][:]=='Gmail'),\\\n",
    "                                        np.sum(data[2][:]=='Contacts'),\\\n",
    "                                        np.sum(data[2][:]=='Internet'),\\\n",
    "                                        np.sum(data[2][:]=='Gallery'),\\\n",
    "                                        np.sum(data[2][:]=='Email'),\\\n",
    "                                        np.sum(data[2][:]=='Settings'),\\\n",
    "                                        np.sum(data[2][:]=='Messenger'),\\\n",
    "                                        np.sum(data[2][:]=='Camera'),\\\n",
    "                                        np.sum(data[2][:]=='Clock'),\\\n",
    "                                        np.sum(data[2][:]=='Maps'),\\\n",
    "                                        np.sum(data[2][:]=='Calendar'),\\\n",
    "                                        np.sum(data[2][:]=='Youtube'),\\\n",
    "                                        np.sum(data[2][:]=='Calculator'),\\\n",
    "                                        np.sum(data[2][:]=='Purple Robot'),\\\n",
    "                                        np.sum(data[2][:]=='System UI')])\n",
    "        else:\n",
    "            ft_row = np.append(ft_row, np.zeros([1,20]))\n",
    "            \n",
    "        # communication\n",
    "        if 'coe.csv' in sensors:\n",
    "            data = pd.read_csv(sensor_dir+'coe.csv', delimiter='\\t', header=None)\n",
    "            n_call_in = np.sum(np.logical_and(data[3][:]=='PHONE',data[4][:]=='INCOMING'))\n",
    "            n_call_out = np.sum(np.logical_and(data[3][:]=='PHONE',data[4][:]=='OUTGOING'))\n",
    "            n_sms_in = np.sum(np.logical_and(data[3][:]=='SMS',data[4][:]=='INCOMING'))\n",
    "            n_sms_out = np.sum(np.logical_and(data[3][:]=='SMS',data[4][:]=='OUTGOING'))\n",
    "            n_missedcall = np.sum(data[4][:]=='MISSED')\n",
    "            ft_row = np.append(ft_row, [n_call_in,n_call_out,n_sms_in,n_sms_out,n_missedcall])\n",
    "        else:\n",
    "            ft_row = np.append(ft_row, [0, 0, 0, 0, 0])\n",
    "        \n",
    "        # wifi\n",
    "        if 'wif.csv' in sensors:\n",
    "            data = pd.read_csv(sensor_dir+'wif.csv', delimiter='\\t', header=None)\n",
    "            ft_row = np.append(ft_row, np.mean(data[3][:]))\n",
    "        else:\n",
    "            ft_row = np.append(ft_row, np.nan)\n",
    "        \n",
    "        # GPS \n",
    "        if 'fus.csv' in sensors:\n",
    "            data = pd.read_csv(sensor_dir+'fus.csv', delimiter='\\t', header=None)\n",
    "            t_start = data[0][0]\n",
    "            t_end = data[0][data[0][:].size-1]\n",
    "            lat = data[1][:]\n",
    "            lng = data[2][:]\n",
    "            ft_row = np.append(ft_row, [np.mean(lat), np.mean(lng), np.log(np.var(lat)+np.var(lng)+1e-16)])\n",
    "        else:\n",
    "            ft_row = np.append(ft_row,[np.nan, np.nan, np.nan])\n",
    "        \n",
    "        # weather\n",
    "        if 'wtr.csv' in sensors:\n",
    "            data = pd.read_csv(sensor_dir+'wtr.csv', delimiter='\\t', header=None)\n",
    "            wtr_cond = stats.mode(data[9][:])[0][0]\n",
    "            if not isinstance(wtr_cond, basestring):\n",
    "                wtr_cond = str(wtr_cond)\n",
    "            ft_row = np.append(ft_row, [np.mean(data[1][:]), np.mean(data[3][:]), sum(ord(c) for c in wtr_cond)])\n",
    "        else:\n",
    "            ft_row = np.append(ft_row, [np.nan, np.nan, np.nan])\n",
    "        \n",
    "        # time\n",
    "        dow_start = datetime.datetime.fromtimestamp(t_start).weekday()\n",
    "        dow_end = datetime.datetime.fromtimestamp(t_end).weekday()\n",
    "        ft_row = np.append(ft_row, [t_end-t_start, ((t_end+t_start)/2.0)%86400, dow_start, dow_end])\n",
    "        \n",
    "        # foursquare location\n",
    "        loc_fsq_code = le.transform(loc_fsq)\n",
    "        loc_fsq_bin = enc.transform(loc_fsq_code.reshape(-1,1)).toarray()            \n",
    "        ft_row = np.append(ft_row, loc_fsq_bin[0])\n",
    "        \n",
    "        # distance to closest foursquare location (m)\n",
    "        ft_row = np.append(ft_row, distance_fsq)\n",
    "\n",
    "        # adding to feature matrix\n",
    "        if i==0:\n",
    "            feature = np.array([ft_row])\n",
    "            state = np.array(loc)\n",
    "            state_fsq = np.array(loc_fsq)\n",
    "        else:\n",
    "            feature = np.append(feature, [ft_row], axis=0)\n",
    "            state = np.append(state, loc)\n",
    "            state_fsq = np.append(state_fsq, loc_fsq)\n",
    "        \n",
    "    if save_results:\n",
    "        with open('features_new/features_'+subj+'.dat', 'w') as file_out:\n",
    "            pickle.dump([feature, state, state_fsq, feature_label], file_out)\n",
    "        file_out.close()\n",
    "\n",
    "os._exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# spatial visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "colors = plt.cm.jet(np.linspace(0,1,len(loc_uniq)))\n",
    "plt.figure(figsize=(18,15))\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.plot(np.array(lng_gps),np.array(lat_gps),'ko',alpha=0.1, markersize=12)\n",
    "for i in range(len(loc_uniq)):\n",
    "    inds = loc.index(loc_uniq[i])\n",
    "    plt.plot(np.array(lng_report[inds]), np.array(lat_report[inds]), 'o', color=colors[i], alpha=1, markersize=12)\n",
    "plt.legend(['gps']+loc_uniq, frameon=False, loc='center left', bbox_to_anchor=(0.6, 0.8))\n",
    "plt.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# temporal visualization\n",
    "from sklearn import preprocessing\n",
    "print loc\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(loc)\n",
    "loc_code = le.transform(loc)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(loc_code,'.k',markersize=10)\n",
    "plt.yticks(range(len(loc_uniq)), loc_uniq)\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([0, len(loc_code)])\n",
    "axes.set_ylim([-1, len(loc_uniq)])\n",
    "print t_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# temporal visualization\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(state_code,'.k',markersize=10)\n",
    "plt.yticks(range(len(loc_uniq)), loc_uniq)\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([0, len(state_code)])\n",
    "axes.set_ylim([-1, len(loc_uniq)])\n",
    "print loc_uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# distribution of features across locations\n",
    "ft = 0\n",
    "plt.figure(figsize=(18,8))\n",
    "plt.plot(state_code+np.random.uniform(-.1,.1,len(state_code)), feature[:,ft],'.',markersize=20, alpha=.5)\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([-.5, len(loc_uniq)-.5])\n",
    "plt.xticks(range(len(loc_uniq)), loc_uniq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
