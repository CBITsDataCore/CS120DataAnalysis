{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ipyparallel import Client\n",
    "\n",
    "rc = Client()\n",
    "dv = rc[:]\n",
    "\n",
    "@dv.parallel(block = True)\n",
    "def extract_features(subjects):\n",
    "\n",
    "    from preprocess import preprocess_location, preprocess_reason\n",
    "    import csv\n",
    "    import os\n",
    "    import numpy as np\n",
    "    from get_data_at_location import get_data_at_location\n",
    "    from calculate_confusion_matrix import calculate_confusion_matrix\n",
    "    import math\n",
    "    import pickle\n",
    "    import pandas as pd\n",
    "    import datetime\n",
    "    from scipy import stats\n",
    "    from count_transitions import count_transitions\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from sklearn import preprocessing\n",
    "\n",
    "    save_results = True\n",
    "    break_locations = False \n",
    "    remove_vehicle = True\n",
    "\n",
    "    data_dir = 'data/'\n",
    "\n",
    "    # subjects = os.listdir('data/')\n",
    "    # subjects = [subjects[0]]\n",
    "\n",
    "    # Foursquare name : dataset name\n",
    "    fsq_map = {'Nightlife Spot':'Nightlife Spot',\\\n",
    "               'Outdoors & Recreation':'Outdoors & Recreation',\\\n",
    "               'Arts & Entertainment':'Arts & Entertainment',\\\n",
    "               'Professional & Other Places':'Professional Or Medical Office',\\\n",
    "               'Food':'Food',\\\n",
    "               'Residence':'Home',\\\n",
    "               'Shop & Service':'Shop Or Store', \\\n",
    "               'Travel & Transport':'Travel Or Transport'}\n",
    "\n",
    "    # building one hot encoder for foursquare locations (as extra features)\n",
    "    state7 = np.array(list(fsq_map.values())+['Unknown'])\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(state7)\n",
    "    state7_code = le.transform(state7)\n",
    "    enc = OneHotEncoder()\n",
    "    enc.fit(state7_code.reshape(-1, 1))\n",
    "\n",
    "    for subj in subjects:\n",
    "\n",
    "        print(subj)\n",
    "\n",
    "        subject_dir = data_dir + subj + '/'\n",
    "        samples = os.listdir(subject_dir)\n",
    "\n",
    "        # initialization\n",
    "        feature = pd.DataFrame()\n",
    "        target = pd.DataFrame()\n",
    "\n",
    "        ind_last = 0\n",
    "\n",
    "        for (i,samp) in enumerate(samples):\n",
    "\n",
    "            sensor_dir = subject_dir + samp + '/'\n",
    "            sensors = os.listdir(sensor_dir)\n",
    "\n",
    "            # reading semantic location data and skipping if it does not exist\n",
    "            if 'eml.csv' in sensors:\n",
    "                filename = sensor_dir+'eml.csv'\n",
    "                data = pd.read_csv(filename, delimiter='\\t', header=None)\n",
    "\n",
    "                # removing Vehicle category\n",
    "                if remove_vehicle and data.loc[0,6]=='[\"Vehicle\"]':\n",
    "                    print('vehicle category skipped')\n",
    "                    continue\n",
    "\n",
    "                # generate separate locations for each of the reported locations\n",
    "                if break_locations:\n",
    "                    target.loc[ind_last, 'location'] = data.loc[0,6]\n",
    "                else:\n",
    "                    target.loc[ind_last, 'location'] = preprocess_location(data.loc[0,6], parse=False)\n",
    "\n",
    "                target.loc[ind_last, 'reason'] = preprocess_reason(data.loc[0,7], parse=False)\n",
    "                target.loc[ind_last, 'accomplishment'] = data.loc[0,8]\n",
    "                target.loc[ind_last, 'pleasure'] = data.loc[0,9]\n",
    "            else:\n",
    "                print('subject {} does not have location report data at {}. skipping'.format(subject,samp))\n",
    "                continue\n",
    "\n",
    "            if 'fsq2.csv' in sensors:\n",
    "                data_fsq = pd.read_csv(sensor_dir+'fsq2.csv', delimiter='\\t', header=None)\n",
    "                loc_fsq = data_fsq.loc[10,1]\n",
    "                distance_fsq = float(data_fsq.loc[11,1])\n",
    "\n",
    "                # converting foursquare category name to standard name\n",
    "                if loc_fsq in fsq_map:\n",
    "                    loc_fsq = fsq_map[loc_fsq]\n",
    "                else:\n",
    "                    loc_fsq = 'Unknown'\n",
    "\n",
    "            else:\n",
    "                loc_fsq = 'Unknown'\n",
    "                distance_fsq = np.nan\n",
    "\n",
    "            target.loc[ind_last, 'fsq'] = loc_fsq\n",
    "\n",
    "            ## sensor features\n",
    "            # light\n",
    "            if 'lgt.csv' in sensors:\n",
    "                data = pd.read_csv(sensor_dir+'lgt.csv', delimiter='\\t', header=None)\n",
    "                lgt = data[:][1]\n",
    "                feature.loc[ind_last, 'lgt mean'] = np.nanmean(lgt)\n",
    "                feature.loc[ind_last, 'lgt std'] = np.nanstd(lgt)\n",
    "                feature.loc[ind_last, 'lgt off'] = np.sum(lgt==0)/float(lgt.size)\n",
    "                feature.loc[ind_last, 'lgt zcrossing'] = np.sum(np.diff(np.sign(lgt-np.nanmean(lgt))))/float(lgt.size)\n",
    "                feature.loc[ind_last, 'lgt skew'] = stats.skew(lgt)\n",
    "                feature.loc[ind_last, 'lgt kurt'] = stats.kurtosis(lgt)\n",
    "            else:\n",
    "                feature.loc[ind_last, 'lgt mean'] = np.nan\n",
    "                feature.loc[ind_last, 'lgt std'] = np.nan\n",
    "                feature.loc[ind_last, 'lgt off'] = np.nan\n",
    "                feature.loc[ind_last, 'lgt zcrossing'] = np.nan\n",
    "                feature.loc[ind_last, 'lgt skew'] = np.nan\n",
    "                feature.loc[ind_last, 'lgt kurt'] = np.nan\n",
    "\n",
    "            # audio\n",
    "            if 'aud.csv' in sensors:\n",
    "                data = pd.read_csv(sensor_dir+'aud.csv', delimiter='\\t', header=None)\n",
    "                feature.loc[ind_last, 'aud mean'] = np.nanmean(data[:][1])\n",
    "                feature.loc[ind_last, 'aud std'] = np.nanstd(data[:][1])\n",
    "                feature.loc[ind_last, 'aud skew'] = stats.skew(data[:][1])\n",
    "                feature.loc[ind_last, 'aud kurt'] = stats.kurtosis(data[:][1])\n",
    "                feature.loc[ind_last, 'aud frq mean'] = np.nanmean(data[:][2])\n",
    "                feature.loc[ind_last, 'aud frq std'] = np.nanstd(data[:][2])\n",
    "                feature.loc[ind_last, 'aud frq skew'] = stats.skew(data[:][2])\n",
    "                feature.loc[ind_last, 'aud frq kurt'] = stats.kurtosis(data[:][2])\n",
    "            else:\n",
    "                feature.loc[ind_last, 'aud mean'] = np.nan\n",
    "                feature.loc[ind_last, 'aud std'] = np.nan\n",
    "                feature.loc[ind_last, 'aud skew'] = np.nan\n",
    "                feature.loc[ind_last, 'aud kurt'] = np.nan\n",
    "                feature.loc[ind_last, 'aud frq mean'] = np.nan\n",
    "                feature.loc[ind_last, 'aud frq std'] = np.nan\n",
    "                feature.loc[ind_last, 'aud frq skew'] = np.nan\n",
    "                feature.loc[ind_last, 'aud frq kurt'] = np.nan\n",
    "\n",
    "            # screen\n",
    "            if 'scr.csv' in sensors:\n",
    "                data = pd.read_csv(sensor_dir+'scr.csv', delimiter='\\t', header=None)\n",
    "                if data[:][0].size>=2:\n",
    "                    deltat = data[0][data[0][:].size-1] - data[0][0]\n",
    "                    if deltat!=0:\n",
    "                        scr_dur = np.array([])\n",
    "                        scr_frq = 0\n",
    "                        for j in range(data[1][:].size-1):\n",
    "                            if data[1][j]=='True' and data[1][j+1]=='False':\n",
    "                                scr_dur = np.append(scr_dur, data[0][j+1]-data[0][j])\n",
    "                                scr_frq += 1\n",
    "                        feature.loc[ind_last, 'scr frq'] = scr_frq/float(deltat)\n",
    "                        feature.loc[ind_last, 'scr dur mean'] = np.mean(scr_dur)\n",
    "                        feature.loc[ind_last, 'scr dur std'] = np.std(scr_dur)\n",
    "                    else:\n",
    "                        feature.loc[ind_last, 'scr frq'] = np.nan\n",
    "                        feature.loc[ind_last, 'scr dur mean'] = np.nan\n",
    "                        feature.loc[ind_last, 'scr dur std'] = np.nan\n",
    "                else:\n",
    "                    feature.loc[ind_last, 'scr frq'] = 0\n",
    "                    feature.loc[ind_last, 'scr dur mean'] = 0\n",
    "                    feature.loc[ind_last, 'scr dur std'] = np.nan\n",
    "            else:\n",
    "                feature.loc[ind_last, 'scr frq'] = 0\n",
    "                feature.loc[ind_last, 'scr dur mean'] = 0\n",
    "                feature.loc[ind_last, 'scr dur std'] = np.nan\n",
    "\n",
    "            # activity\n",
    "            if 'act.csv' in sensors:\n",
    "                data = pd.read_csv(sensor_dir+'act.csv', delimiter='\\t', header=None)\n",
    "                n = float(data[0][:].size)\n",
    "                feature.loc[ind_last, 'still'] = np.sum(data[1][:]=='STILL')/n\n",
    "                feature.loc[ind_last, 'tilting'] = np.sum(data[1][:]=='TILTING')/n\n",
    "                feature.loc[ind_last, 'walking'] = np.sum(data[1][:]=='ONFOOT')/n\n",
    "                feature.loc[ind_last, 'unknown act'] = np.sum(data[1][:]=='UNKNOWN')/n\n",
    "                feature.loc[ind_last, 'still-walking'] = count_transitions(data[1][:],'STILL','ONFOOT')/n\n",
    "                feature.loc[ind_last, 'still-tilting'] = count_transitions(data[1][:],'STILL','TILTING')/n\n",
    "                feature.loc[ind_last, 'still-unknown'] = count_transitions(data[1][:],'STILL','UNKNOWN')/n\n",
    "                feature.loc[ind_last, 'walking-unknown'] = count_transitions(data[1][:],'ONFOOT','UNKNOWN')/n\n",
    "            else:\n",
    "                feature.loc[ind_last, 'still'] = np.nan\n",
    "                feature.loc[ind_last, 'tilting'] = np.nan\n",
    "                feature.loc[ind_last, 'walking'] = np.nan\n",
    "                feature.loc[ind_last, 'unknown act'] = np.nan\n",
    "                feature.loc[ind_last, 'still-walking'] = np.nan\n",
    "                feature.loc[ind_last, 'still-tilting'] = np.nan\n",
    "                feature.loc[ind_last, 'still-unknown'] = np.nan\n",
    "                feature.loc[ind_last, 'walking-unknown'] = np.nan\n",
    "\n",
    "            # apps\n",
    "    #             if 'app.csv' in sensors:\n",
    "    #                 data = pd.read_csv(sensor_dir+'app.csv', delimiter='\\t', header=None)\n",
    "    #                 feature.loc[ind_last, 'messaging'] = np.sum(data[2][:]=='Messaging')\n",
    "    #                 feature.loc[ind_last, 'facebook'] = np.sum(data[2][:]=='Facebook')\n",
    "    #                 feature.loc[ind_last, 'chrome'] = np.sum(data[2][:]=='Chrome')\n",
    "    #                 feature.loc[ind_last, 'mobilyze'] = np.sum(data[2][:]=='Mobilyze')\n",
    "    #                 feature.loc[ind_last, 'phone'] = np.sum(data[2][:]=='Phone')\n",
    "    #                 feature.loc[ind_last, 'gmail'] = np.sum(data[2][:]=='Gmail')\n",
    "    #                 feature.loc[ind_last, 'contacts'] = np.sum(data[2][:]=='Contacts')\n",
    "    #                 feature.loc[ind_last, 'internet'] = np.sum(data[2][:]=='Internet')\n",
    "    #                 feature.loc[ind_last, 'gallery'] = np.sum(data[2][:]=='Gallery')\n",
    "    #                 feature.loc[ind_last, 'email'] = np.sum(data[2][:]=='Email')\n",
    "    #                 feature.loc[ind_last, 'settings'] = np.sum(data[2][:]=='Settings')\n",
    "    #                 feature.loc[ind_last, 'messenger'] = np.sum(data[2][:]=='Messenger')\n",
    "    #                 feature.loc[ind_last, 'camera'] = np.sum(data[2][:]=='Camera')\n",
    "    #                 feature.loc[ind_last, 'clock'] = np.sum(data[2][:]=='Clock')\n",
    "    #                 feature.loc[ind_last, 'maps'] = np.sum(data[2][:]=='Maps')\n",
    "    #                 feature.loc[ind_last, 'calendar'] = np.sum(data[2][:]=='Calendar')\n",
    "    #                 feature.loc[ind_last, 'youtube'] = np.sum(data[2][:]=='Youtube')\n",
    "    #                 feature.loc[ind_last, 'calculator'] = np.sum(data[2][:]=='Calculator')\n",
    "    #                 feature.loc[ind_last, 'purple robot'] = np.sum(data[2][:]=='Purple Robot')\n",
    "    #                 feature.loc[ind_last, 'system ui'] = np.sum(data[2][:]=='System UI')\n",
    "    #             else:\n",
    "    #                 if has_app_data: # if not, leave them as NaN\n",
    "    #                     feature.loc[ind_last, 'messaging'] = 0\n",
    "    #                     feature.loc[ind_last, 'facebook'] = 0\n",
    "    #                     feature.loc[ind_last, 'chrome'] = 0\n",
    "    #                     feature.loc[ind_last, 'mobilyze'] = 0\n",
    "    #                     feature.loc[ind_last, 'phone'] = 0\n",
    "    #                     feature.loc[ind_last, 'gmail'] = 0\n",
    "    #                     feature.loc[ind_last, 'contacts'] = 0\n",
    "    #                     feature.loc[ind_last, 'internet'] = 0\n",
    "    #                     feature.loc[ind_last, 'gallery'] = 0\n",
    "    #                     feature.loc[ind_last, 'email'] = 0\n",
    "    #                     feature.loc[ind_last, 'settings'] = 0\n",
    "    #                     feature.loc[ind_last, 'messenger'] = 0\n",
    "    #                     feature.loc[ind_last, 'camera'] = 0\n",
    "    #                     feature.loc[ind_last, 'clock'] = 0\n",
    "    #                     feature.loc[ind_last, 'maps'] = 0\n",
    "    #                     feature.loc[ind_last, 'calendar'] = 0\n",
    "    #                     feature.loc[ind_last, 'youtube'] = 0\n",
    "    #                     feature.loc[ind_last, 'calculator'] = 0\n",
    "    #                     feature.loc[ind_last, 'purple robot'] = 0\n",
    "    #                     feature.loc[ind_last, 'system ui'] = 0\n",
    "    #                 else:\n",
    "    #                     feature.loc[ind_last, 'messaging'] = np.nan\n",
    "    #                     feature.loc[ind_last, 'facebook'] = np.nan\n",
    "    #                     feature.loc[ind_last, 'chrome'] = np.nan\n",
    "    #                     feature.loc[ind_last, 'mobilyze'] = np.nan\n",
    "    #                     feature.loc[ind_last, 'phone'] = np.nan\n",
    "    #                     feature.loc[ind_last, 'gmail'] = np.nan\n",
    "    #                     feature.loc[ind_last, 'contacts'] = np.nan\n",
    "    #                     feature.loc[ind_last, 'internet'] = np.nan\n",
    "    #                     feature.loc[ind_last, 'gallery'] = np.nan\n",
    "    #                     feature.loc[ind_last, 'email'] = np.nan\n",
    "    #                     feature.loc[ind_last, 'settings'] = np.nan\n",
    "    #                     feature.loc[ind_last, 'messenger'] = np.nan\n",
    "    #                     feature.loc[ind_last, 'camera'] = np.nan\n",
    "    #                     feature.loc[ind_last, 'clock'] = np.nan\n",
    "    #                     feature.loc[ind_last, 'maps'] = np.nan\n",
    "    #                     feature.loc[ind_last, 'calendar'] = np.nan\n",
    "    #                     feature.loc[ind_last, 'youtube'] = np.nan\n",
    "    #                     feature.loc[ind_last, 'calculator'] = np.nan\n",
    "    #                     feature.loc[ind_last, 'purple robot'] = np.nan\n",
    "    #                     feature.loc[ind_last, 'system ui'] = np.nan\n",
    "\n",
    "            # communication\n",
    "            if 'coe.csv' in sensors:\n",
    "                data = pd.read_csv(sensor_dir+'coe.csv', delimiter='\\t', header=None)\n",
    "                feature.loc[ind_last, 'call in'] = np.sum(np.logical_and(data[3][:]=='PHONE',data[4][:]=='INCOMING'))\n",
    "                feature.loc[ind_last, 'call out'] = np.sum(np.logical_and(data[3][:]=='PHONE',data[4][:]=='OUTGOING'))\n",
    "                feature.loc[ind_last, 'sms in'] = np.sum(np.logical_and(data[3][:]=='SMS',data[4][:]=='INCOMING'))\n",
    "                feature.loc[ind_last, 'sms out'] = np.sum(np.logical_and(data[3][:]=='SMS',data[4][:]=='OUTGOING'))\n",
    "                feature.loc[ind_last, 'call missed'] = np.sum(data[4][:]=='MISSED')\n",
    "            else:\n",
    "                feature.loc[ind_last, 'call in'] = 0\n",
    "                feature.loc[ind_last, 'call out'] = 0\n",
    "                feature.loc[ind_last, 'sms in'] = 0\n",
    "                feature.loc[ind_last, 'sms out'] = 0\n",
    "                feature.loc[ind_last, 'call missed'] = 0\n",
    "\n",
    "            # wifi\n",
    "            if 'wif.csv' in sensors:\n",
    "                data = pd.read_csv(sensor_dir+'wif.csv', delimiter='\\t', header=None)\n",
    "                feature.loc[ind_last, 'n wifi'] = np.mean(data[3][:])\n",
    "            else:\n",
    "                feature.loc[ind_last, 'n wifi'] = np.nan\n",
    "\n",
    "            # weather\n",
    "            if 'wtr.csv' in sensors:\n",
    "                data = pd.read_csv(sensor_dir+'wtr.csv', delimiter='\\t', header=None)\n",
    "                wtr_cond = stats.mode(data[9][:])[0][0]\n",
    "                if not isinstance(wtr_cond, str):\n",
    "                    wtr_cond = str(wtr_cond)\n",
    "                feature.loc[ind_last, 'temperature'] = np.mean(data[1][:])\n",
    "                feature.loc[ind_last, 'dew point'] = np.mean(data[3][:])\n",
    "                feature.loc[ind_last, 'weather'] = sum(ord(c) for c in wtr_cond)\n",
    "            else:\n",
    "                feature.loc[ind_last, 'temperature'] = np.nan\n",
    "                feature.loc[ind_last, 'dew point'] = np.nan\n",
    "                feature.loc[ind_last, 'weather'] = np.nan\n",
    "\n",
    "            # GPS and time\n",
    "            if 'fus.csv' in sensors:\n",
    "                data = pd.read_csv(sensor_dir+'fus.csv', delimiter='\\t', header=None)\n",
    "                t_start = data[0][0]\n",
    "                t_end = data[0][data[0][:].size-1]\n",
    "                feature.loc[ind_last, 'lat mean'] = np.mean(data[1][:])\n",
    "                feature.loc[ind_last, 'lng mean'] = np.mean(data[2][:])\n",
    "                feature.loc[ind_last, 'loc var'] = np.log(np.var(data[1][:])+np.var(data[2][:])+1e-16)\n",
    "                feature.loc[ind_last, 'duration'] = t_end-t_start\n",
    "                feature.loc[ind_last, 'midtime'] = (t_end+t_start)/2.0\n",
    "                feature.loc[ind_last, 'midhour'] = ((t_end+t_start)/2.0)%86400\n",
    "                feature.loc[ind_last, 'dow start'] = datetime.datetime.fromtimestamp(t_start).weekday()\n",
    "                feature.loc[ind_last, 'dow end'] = datetime.datetime.fromtimestamp(t_end).weekday()\n",
    "                feature.loc[ind_last, 'n gps'] = data.shape[0]\n",
    "            else:\n",
    "                feature.loc[ind_last, 'lat mean'] = np.nan\n",
    "                feature.loc[ind_last, 'lng mean'] = np.nan\n",
    "                feature.loc[ind_last, 'loc var'] = np.nan\n",
    "                feature.loc[ind_last, 'duration'] = np.nan\n",
    "                feature.loc[ind_last, 'midtime'] = np.nan\n",
    "                feature.loc[ind_last, 'midhour'] = np.nan\n",
    "                feature.loc[ind_last, 'dow start'] = np.nan\n",
    "                feature.loc[ind_last, 'dow end'] = np.nan\n",
    "                feature.loc[ind_last, 'n gps'] = 0.0\n",
    "\n",
    "            # foursquare location in binary form\n",
    "            loc_fsq_code = le.transform(np.array([loc_fsq]))\n",
    "            loc_fsq_bin = enc.transform(loc_fsq_code.reshape(-1,1)).toarray()\n",
    "            loc_fsq_bin = loc_fsq_bin[0]\n",
    "            for j in range(loc_fsq_bin.size):\n",
    "                feature.loc[ind_last, 'fsq {}'.format(j)] = loc_fsq_bin[j]\n",
    "\n",
    "            # distance to closest foursquare location (m)\n",
    "            feature.loc[ind_last, 'fsq distance'] = distance_fsq\n",
    "\n",
    "            # break locations and generate duplicate data for other sensors\n",
    "            if break_locations:\n",
    "                locs = target.loc[ind_last, 'location']\n",
    "                locs = locs[1:-1] # remove brackets\n",
    "                locs = locs.split('\", \"')\n",
    "                locs = [l.replace('\"','') for l in locs]\n",
    "                locs = filter(None, locs) # remove any empty strings\n",
    "                # first repeating everything\n",
    "                for i in range(len(locs)-1):\n",
    "                    target.loc[ind_last+1+i,:] = target.loc[ind_last,:]\n",
    "                    feature.loc[ind_last+1+i,:] = feature.loc[ind_last,:]\n",
    "                # noew replacing locations with new values\n",
    "                for (i,_) in enumerate(locs):\n",
    "                    target.loc[ind_last+i,'location'] = locs[i]\n",
    "                # last index\n",
    "                ind_last += len(locs)\n",
    "\n",
    "            else:\n",
    "                ind_last += 1\n",
    "\n",
    "        if save_results:\n",
    "            with open('features/'+subj+'.dat', 'wb') as file_out:\n",
    "                pickle.dump([feature, target], file_out)\n",
    "            file_out.close()\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject 1515656 removed due to spoofed gps.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "subjects = os.listdir('data/')\n",
    "subjects.remove('1515656')\n",
    "print('subject 1515656 removed due to spoofed gps.')\n",
    "extract_features(subjects)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
